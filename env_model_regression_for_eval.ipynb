{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import pickle\n",
    "import math\n",
    "import copy"
   ]
  },
  
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_features = ['MIMICzs1','MIMICzs2','MIMICzs3','MIMICzs4','MIMICzs5','MIMICzs6','MIMICzs7','MIMICzs8','MIMICzs9','MIMICzs10','MIMICzs11','MIMICzs12','MIMICzs13','MIMICzs14','MIMICzs15','MIMICzs16','MIMICzs17','MIMICzs18','MIMICzs19','MIMICzs20','MIMICzs21','MIMICzs22','MIMICzs23','MIMICzs24','MIMICzs25','MIMICzs26','MIMICzs27','MIMICzs28','MIMICzs29','MIMICzs30','MIMICzs31','MIMICzs32','MIMICzs33','MIMICzs34','MIMICzs35','MIMICzs36','MIMICzs37','MIMICzs38','MIMICzs39','MIMICzs40','MIMICzs41','MIMICzs42','MIMICzs43','MIMICzs44','MIMICzs45','MIMICzs46','MIMICzs47', 'abchange_vc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(state_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_vasochange/train_withterm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bloc</th>\n",
       "      <th>icustayid</th>\n",
       "      <th>mortality_90d</th>\n",
       "      <th>MIMICzs1</th>\n",
       "      <th>MIMICzs2</th>\n",
       "      <th>MIMICzs3</th>\n",
       "      <th>MIMICzs4</th>\n",
       "      <th>MIMICzs5</th>\n",
       "      <th>MIMICzs6</th>\n",
       "      <th>MIMICzs7</th>\n",
       "      <th>...</th>\n",
       "      <th>MIMICzs44</th>\n",
       "      <th>MIMICzs45</th>\n",
       "      <th>MIMICzs46</th>\n",
       "      <th>MIMICzs47</th>\n",
       "      <th>action</th>\n",
       "      <th>shaped_reward</th>\n",
       "      <th>io_ac</th>\n",
       "      <th>vc_ac</th>\n",
       "      <th>abchange_vc</th>\n",
       "      <th>max_dose_vaso</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-2.302585</td>\n",
       "      <td>-0.978344</td>\n",
       "      <td>-0.187300</td>\n",
       "      <td>0.705956</td>\n",
       "      <td>...</td>\n",
       "      <td>0.391651</td>\n",
       "      <td>0.52761</td>\n",
       "      <td>0.786192</td>\n",
       "      <td>0.702781</td>\n",
       "      <td>10</td>\n",
       "      <td>-1.224270</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-2.302585</td>\n",
       "      <td>-0.978344</td>\n",
       "      <td>-0.187300</td>\n",
       "      <td>0.705956</td>\n",
       "      <td>...</td>\n",
       "      <td>0.394176</td>\n",
       "      <td>0.52761</td>\n",
       "      <td>0.793676</td>\n",
       "      <td>0.596530</td>\n",
       "      <td>10</td>\n",
       "      <td>1.640796</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-2.302585</td>\n",
       "      <td>-0.978344</td>\n",
       "      <td>-0.187300</td>\n",
       "      <td>0.705956</td>\n",
       "      <td>...</td>\n",
       "      <td>0.396682</td>\n",
       "      <td>0.52761</td>\n",
       "      <td>0.799286</td>\n",
       "      <td>0.516950</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.025000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-2.302585</td>\n",
       "      <td>-0.978344</td>\n",
       "      <td>-0.155313</td>\n",
       "      <td>0.705956</td>\n",
       "      <td>...</td>\n",
       "      <td>0.399169</td>\n",
       "      <td>0.52761</td>\n",
       "      <td>0.805952</td>\n",
       "      <td>0.575231</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.025000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-2.302585</td>\n",
       "      <td>-0.978344</td>\n",
       "      <td>-0.147317</td>\n",
       "      <td>0.705956</td>\n",
       "      <td>...</td>\n",
       "      <td>0.401637</td>\n",
       "      <td>0.52761</td>\n",
       "      <td>0.816227</td>\n",
       "      <td>0.714111</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.025000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   bloc  icustayid  mortality_90d  MIMICzs1  MIMICzs2  MIMICzs3  MIMICzs4  \\\n",
       "0     1          3              1      -0.5      -0.5      -0.5 -2.302585   \n",
       "1     2          3              1      -0.5      -0.5      -0.5 -2.302585   \n",
       "2     3          3              1      -0.5      -0.5      -0.5 -2.302585   \n",
       "3     4          3              1      -0.5      -0.5      -0.5 -2.302585   \n",
       "4     5          3              1      -0.5      -0.5      -0.5 -2.302585   \n",
       "\n",
       "   MIMICzs5  MIMICzs6  MIMICzs7      ...        MIMICzs44  MIMICzs45  \\\n",
       "0 -0.978344 -0.187300  0.705956      ...         0.391651    0.52761   \n",
       "1 -0.978344 -0.187300  0.705956      ...         0.394176    0.52761   \n",
       "2 -0.978344 -0.187300  0.705956      ...         0.396682    0.52761   \n",
       "3 -0.978344 -0.155313  0.705956      ...         0.399169    0.52761   \n",
       "4 -0.978344 -0.147317  0.705956      ...         0.401637    0.52761   \n",
       "\n",
       "   MIMICzs46  MIMICzs47  action  shaped_reward  io_ac  vc_ac  abchange_vc  \\\n",
       "0   0.786192   0.702781      10      -1.224270      2      0          0.0   \n",
       "1   0.793676   0.596530      10       1.640796      2      0          0.0   \n",
       "2   0.799286   0.516950      10      -0.025000      2      0          0.0   \n",
       "3   0.805952   0.575231      10      -0.025000      2      0          0.0   \n",
       "4   0.816227   0.714111      10      -0.025000      2      0          0.0   \n",
       "\n",
       "   max_dose_vaso  \n",
       "0            0.0  \n",
       "1            0.0  \n",
       "2            0.0  \n",
       "3            0.0  \n",
       "4            0.0  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = pd.read_csv('data_vasochange/val_withterm.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('data_vasochange/test_withterm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define an action mapping - how to get an id representing the action from the (iv,vaso) tuple\n",
    "action_map = {}\n",
    "count = 0\n",
    "for iv in range(5):\n",
    "    for vaso in range(5):\n",
    "        action_map[(iv,vaso)] = count\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(0, 0): 0, (0, 1): 1, (0, 2): 2, (0, 3): 3, (0, 4): 4, (1, 0): 5, (1, 1): 6, (1, 2): 7, (1, 3): 8, (1, 4): 9, (2, 0): 10, (2, 1): 11, (2, 2): 12, (2, 3): 13, (2, 4): 14, (3, 0): 15, (3, 1): 16, (3, 2): 17, (3, 3): 18, (3, 4): 19, (4, 0): 20, (4, 1): 21, (4, 2): 22, (4, 3): 23, (4, 4): 24}\n"
     ]
    }
   ],
   "source": [
    "print(action_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_action_map = {}\n",
    "for iv in range(5):\n",
    "    for vaso in range(5):\n",
    "        inv_action_map[5*iv+vaso] = [iv,vaso]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [0, 0], 1: [0, 1], 2: [0, 2], 3: [0, 3], 4: [0, 4], 5: [1, 0], 6: [1, 1], 7: [1, 2], 8: [1, 3], 9: [1, 4], 10: [2, 0], 11: [2, 1], 12: [2, 2], 13: [2, 3], 14: [2, 4], 15: [3, 0], 16: [3, 1], 17: [3, 2], 18: [3, 3], 19: [3, 4], 20: [4, 0], 21: [4, 1], 22: [4, 2], 23: [4, 3], 24: [4, 4]}\n"
     ]
    }
   ],
   "source": [
    "print(inv_action_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the actions from the q network\n",
    "q_net_save_dir = 'vasochange4_dqn_normal/'\n",
    "train_actions = pickle.load(open( q_net_save_dir + \"dqn_normal_actions_train.p\", \"rb\" ))\n",
    "val_actions = pickle.load(open( q_net_save_dir + \"dqn_normal_actions_val.p\", \"rb\" ))\n",
    "test_actions = pickle.load(open( q_net_save_dir + \"dqn_normal_actions_test.p\", \"rb\" ))\n",
    "\n",
    "df['agent_actions'] = train_actions\n",
    "df['agent_iv'] = df['agent_actions'].apply(lambda x:inv_action_map[x][0] )\n",
    "df['agent_vaso'] = df['agent_actions'].apply(lambda x:inv_action_map[x][1] )\n",
    "\n",
    "val_df['agent_actions'] = val_actions\n",
    "val_df['agent_iv'] = val_df['agent_actions'].apply(lambda x:inv_action_map[x][0] )\n",
    "val_df['agent_vaso'] = val_df['agent_actions'].apply(lambda x:inv_action_map[x][1] )\n",
    "\n",
    "test_df['agent_actions'] = test_actions\n",
    "test_df['agent_iv'] = test_df['agent_actions'].apply(lambda x:inv_action_map[x][0] )\n",
    "test_df['agent_vaso'] = test_df['agent_actions'].apply(lambda x:inv_action_map[x][1] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# preprocess the actions so that they are zero mean\n",
    "df['iv_input'] = df['io_ac'].apply(lambda x: x/4.0)\n",
    "df['vaso_input'] = df['vc_ac'].apply(lambda x: x/4.0)\n",
    "\n",
    "val_df['iv_input'] = val_df['io_ac'].apply(lambda x: x/4.0)\n",
    "val_df['vaso_input'] = val_df['vc_ac'].apply(lambda x: x/4.0)\n",
    "\n",
    "test_df['iv_input'] = test_df['io_ac'].apply(lambda x: x/4.0)\n",
    "test_df['vaso_input'] = test_df['vc_ac'].apply(lambda x: x/4.0)\n",
    "\n",
    "df['agent_iv'] = df['agent_iv'].apply(lambda x: x/4.0)\n",
    "df['agent_vaso'] = df['agent_vaso'].apply(lambda x: x/4.0)\n",
    "\n",
    "val_df['agent_iv'] = val_df['agent_iv'].apply(lambda x: x/4.0)\n",
    "val_df['agent_vaso'] = val_df['agent_vaso'].apply(lambda x: x/4.0)\n",
    "\n",
    "test_df['agent_iv'] = test_df['agent_iv'].apply(lambda x: x/4.0)\n",
    "test_df['agent_vaso'] = test_df['agent_vaso'].apply(lambda x: x/4.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Gaussian noise to the state features\n",
    "gaussian_shape = df.loc[:, state_features].values.shape\n",
    "noise = np.random.normal(0, 0.03, gaussian_shape)\n",
    "df.loc[:, state_features] += noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_1_size = 500\n",
    "hidden_2_size = 500\n",
    "class EnvModel():\n",
    "    def __init__(self):\n",
    "        self.phase = tf.placeholder(tf.bool)\n",
    "        \n",
    "        self.input_size = len(state_features)\n",
    "\n",
    "        self.cur_state = tf.placeholder(tf.float32, shape=[None, self.input_size],name=\"cur_state\")\n",
    "        self.next_state = tf.placeholder(tf.float32, shape=[None, self.input_size],name=\"next_state\")\n",
    "        \n",
    "        self.done_flags = tf.placeholder(tf.int32, shape=[None], name=\"done_flags\")\n",
    "        \n",
    "        self.actions = tf.placeholder(tf.int32, shape = [None, 2], name=\"actions\")\n",
    "        \n",
    "        self.input = tf.concat([self.cur_state, tf.cast(self.actions, tf.float32)], axis=1)\n",
    "        \n",
    "        self.target = self.next_state - self.cur_state\n",
    "\n",
    "        self.fc_1 = tf.contrib.layers.fully_connected(self.input, hidden_1_size, activation_fn=tf.nn.relu)\n",
    "        self.fc_1_bn = tf.contrib.layers.batch_norm(self.fc_1, center=True, scale=True, is_training=self.phase)\n",
    "        self.fc_2 = tf.contrib.layers.fully_connected(self.fc_1_bn, hidden_2_size, activation_fn=tf.nn.relu)\n",
    "        self.fc_2_bn = tf.contrib.layers.batch_norm(self.fc_2, center=True, scale=True, is_training=self.phase)\n",
    "        \n",
    "        self.output = tf.contrib.layers.fully_connected(self.fc_2_bn, self.input_size, activation_fn = None)\n",
    "        \n",
    "        self.multiplier = tf.expand_dims(1 -self.done_flags, 1)\n",
    "        \n",
    "        self.loss = tf.reduce_mean(tf.multiply(tf.square(self.target-self.output), tf.cast(self.multiplier, tf.float32)))  \n",
    "        \n",
    "        self.est_next_state = self.output + self.cur_state\n",
    "\n",
    "        self.trainer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "        self.update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(self.update_ops):\n",
    "        # Ensures that we execute the update_ops before performing the model update, so batchnorm works\n",
    "            self.update_model = self.trainer.minimize(self.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_train_batch(size):\n",
    "    a = df.sample(n=size)\n",
    "    states = None\n",
    "    actions = None\n",
    "    rewards = None\n",
    "    next_states = None\n",
    "    done_flags = None\n",
    "    for i in a.index:\n",
    "        cur_state = a.ix[i,state_features]\n",
    "        #print(a.ix[i, 'iv_input'])\n",
    "        iv = int(a.ix[i, 'iv_input'])\n",
    "        vaso = int(a.ix[i, 'vaso_input'])\n",
    "        action = np.array([iv,vaso])\n",
    "\n",
    "        \n",
    "        if i != df.index[-1]:\n",
    "            # if not terminal step in trajectory             \n",
    "            if df.ix[i, 'icustayid'] == df.ix[i+1, 'icustayid']:\n",
    "                next_state = df.ix[i + 1, state_features]\n",
    "                done = 0\n",
    "            else:\n",
    "                # trajectory is finished\n",
    "               # print(df.ix[i, 'icustayid'], df.ix[i+1,'icustayid'])\n",
    "                next_state = np.zeros(len(cur_state))\n",
    "                done = 1\n",
    "        else:\n",
    "            # last entry in df is the final state of that trajectory\n",
    "            #print(\"why\")\n",
    "            next_state = np.zeros(len(cur_state))\n",
    "            done = 1\n",
    "\n",
    "        if states is None:\n",
    "            states = copy.deepcopy(cur_state)\n",
    "        else:\n",
    "            states = np.vstack((states,cur_state))\n",
    "\n",
    "        if actions is None:\n",
    "            actions = [action]\n",
    "        else:\n",
    "            actions = np.vstack((actions,action))\n",
    "\n",
    "        if next_states is None:\n",
    "            next_states = copy.deepcopy(next_state)\n",
    "        else:\n",
    "            next_states = np.vstack((next_states,next_state))\n",
    "\n",
    "        if done_flags is None:\n",
    "            done_flags = [done]\n",
    "        else:\n",
    "            done_flags = np.vstack((done_flags,done))\n",
    "    \n",
    "    return (states, np.squeeze(actions), next_states, np.squeeze(done_flags), a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract chunks of length size from the relevant dataframe, and yield these to the caller\n",
    "# final tells us if we want to use AGENT actions, not physician actions\n",
    "def process_eval_batch(size, eval_type = None, final=False):\n",
    "    if eval_type is None:\n",
    "        raise Exception('Provide eval_type to process_eval_batch')\n",
    "    elif eval_type == 'train':\n",
    "        a = df.copy()\n",
    "    elif eval_type == 'val':\n",
    "        a = val_df.copy()\n",
    "    elif eval_type == 'test':\n",
    "        a = test_df.copy()\n",
    "    else:\n",
    "        raise Exception('Unknown eval_type')\n",
    "    count = 0\n",
    "    while count < len(a.index):\n",
    "        states = None\n",
    "        actions = None\n",
    "        rewards = None\n",
    "        next_states = None\n",
    "        done_flags = None\n",
    "\n",
    "        start_idx = count\n",
    "        end_idx = min(len(a.index), count+size)\n",
    "        segment = a.index[start_idx:end_idx]\n",
    "        \n",
    "        for i in segment:\n",
    "            cur_state = a.ix[i,state_features]\n",
    "            \n",
    "            if not final:\n",
    "                iv = int(a.ix[i, 'iv_input'])\n",
    "                vaso = int(a.ix[i, 'vaso_input'])\n",
    "                action = np.array([iv,vaso])\n",
    "            else:\n",
    "                iv = int(a.ix[i, 'agent_iv'])\n",
    "                vaso = int(a.ix[i, 'agent_vaso'])\n",
    "                action = np.array([iv,vaso])\n",
    "            reward = a.ix[i,'shaped_reward']\n",
    "\n",
    "            if i != a.index[-1]:\n",
    "                # if not terminal step in trajectory             \n",
    "                if a.ix[i, 'icustayid'] == a.ix[i+1, 'icustayid']:\n",
    "                    next_state = a.ix[i + 1, state_features]\n",
    "                    done = 0\n",
    "                else:\n",
    "                    # trajectory is finished\n",
    "                    next_state = np.zeros(len(cur_state))\n",
    "                    done = 1\n",
    "            else:\n",
    "                # last entry in df is the final state of that trajectory\n",
    "                next_state = np.zeros(len(cur_state))\n",
    "                done = 1\n",
    "\n",
    "            if states is None:\n",
    "                states = copy.deepcopy(cur_state)\n",
    "            else:\n",
    "                states = np.vstack((states,cur_state))\n",
    "\n",
    "            if actions is None:\n",
    "                actions = [action]\n",
    "            else:\n",
    "                actions = np.vstack((actions,action))\n",
    "\n",
    "            if next_states is None:\n",
    "                next_states = copy.deepcopy(next_state)\n",
    "            else:\n",
    "                next_states = np.vstack((next_states,next_state))\n",
    "\n",
    "            if done_flags is None:\n",
    "                done_flags = [done]\n",
    "            else:\n",
    "                done_flags = np.vstack((done_flags,done))\n",
    "\n",
    "        yield (states, np.squeeze(actions), next_states, np.squeeze(done_flags), a)\n",
    "        \n",
    "        count += size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_eval(eval_type, final=False):\n",
    "    gen = process_eval_batch(size = 1000, eval_type=eval_type, final=final)\n",
    "\n",
    "    error_ret = 0\n",
    "    est_next_states = []\n",
    "\n",
    "    for b in gen:\n",
    "\n",
    "        states,actions,next_states, done_flags, _ = b\n",
    "\n",
    "        est_next_state,loss = sess.run([env_model.est_next_state,env_model.loss], \\\n",
    "            feed_dict={env_model.cur_state:states,\n",
    "                       env_model.next_state:next_states, \n",
    "                       env_model.actions:actions,\n",
    "                       env_model.done_flags:done_flags,\n",
    "                       env_model.phase:False})    \n",
    "        error_ret += loss\n",
    "        est_next_states.append(est_next_state)\n",
    "        #print(len(est_next_state))\n",
    "    print(error_ret)\n",
    "    return np.array(est_next_states), error_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # Don't use all GPUs \n",
    "config.allow_soft_placement = True  # Enable manual control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_save_results():\n",
    "    # get the estimated next states UNDER THE AGENT POLICY based on the trained environment model\n",
    "    est_next_states_train, _ = do_eval(eval_type = 'train', final=True)        \n",
    "    est_next_states_val, _ = do_eval(eval_type = 'val', final=True)        \n",
    "    est_next_states_test, _ = do_eval(eval_type = 'test', final=True)   \n",
    "    \n",
    "    # save everything for later - they're used in policy evaluation and when generating plots\n",
    "    with open(save_dir + 'est_next_states_train.p', 'wb') as f:\n",
    "        pickle.dump(est_next_states_train, f)\n",
    "    with open(save_dir + 'est_next_states_val.p', 'wb') as f:\n",
    "        pickle.dump(est_next_states_val, f)\n",
    "    with open(save_dir + 'est_next_states_test.p', 'wb') as f:\n",
    "        pickle.dump(est_next_states_test, f)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to load model...\n",
      "INFO:tensorflow:Restoring parameters from ./env_model_regression/ckpt\n",
      "Model restored\n",
      "Init done\n",
      "Calling do save results\n",
      "90.18003879487514\n",
      "10.320474326610565\n",
      "10.488600730895996\n",
      "90.18003879487514\n",
      "10.320474326610565\n",
      "10.488600730895996\n"
     ]
    }
   ],
   "source": [
    "# The main training loop is here\n",
    "batch_size = 32\n",
    "num_steps = 60000 # How many steps to train for\n",
    "load_model = True #Whether to load a saved model.\n",
    "save_dir = \"./env_model_regression/\"\n",
    "save_path = \"./env_model_regression/ckpt\"#The path to save our model to.rk\n",
    "tf.reset_default_graph()\n",
    "env_model = EnvModel()\n",
    "val_abserror_list = []\n",
    "abs_error_list = []\n",
    "save_results = True\n",
    "\n",
    "saver = tf.train.Saver(tf.global_variables())\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "trainables = tf.trainable_variables()\n",
    "\n",
    "#Make a path for our model to be saved in.\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "    if load_model == True:\n",
    "        print('Trying to load model...')\n",
    "        try:\n",
    "            restorer = tf.train.import_meta_graph(save_path + '.meta')\n",
    "            restorer.restore(sess, tf.train.latest_checkpoint(save_dir))\n",
    "            print(\"Model restored\")\n",
    "        except IOError:\n",
    "            print(\"No previous model found, running default init\")\n",
    "            sess.run(init)\n",
    "    else:\n",
    "        print(\"Running default init\")\n",
    "        sess.run(init)\n",
    "    print(\"Init done\")\n",
    "    \n",
    "    net_loss = 0.0\n",
    "    for i in range(num_steps):\n",
    "        if save_results:\n",
    "            print(\"Calling do save results\")\n",
    "            do_save_results()\n",
    "            break\n",
    "        \n",
    "        states,actions,next_states, done_flags, sampled_df = process_train_batch(batch_size)\n",
    "\n",
    "        # Train with the batch\n",
    "        _,loss = sess.run([env_model.update_model,env_model.loss], \\\n",
    "            feed_dict={env_model.cur_state:states,\n",
    "                       env_model.next_state:next_states, \n",
    "                       env_model.actions:actions,\n",
    "                       env_model.done_flags:done_flags,\n",
    "                       env_model.phase:True})\n",
    "        net_loss += loss\n",
    "    \n",
    "        \n",
    "        if i % 1000 == 0 and i > 0:\n",
    "            saver.save(sess,save_path)\n",
    "            print(\"Saved Model, step is \" + str(i))           \n",
    "            av_loss = net_loss/(1000.0 * batch_size)\n",
    "            abs_error_list.append(av_loss)\n",
    "            print(\"Average loss is \", av_loss)\n",
    "            net_loss = 0.0\n",
    "        \n",
    "            # run an evaluation on the validation set\n",
    "            _, error = do_eval(eval_type = 'val')  \n",
    "            val_abserror_list.append(error/29)\n",
    "            print(error)\n",
    "            if (i % 30000==0) and i > 0:\n",
    "                print(\"Saving results\")\n",
    "                do_save_results()\n",
    "    do_save_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(abs_error_list, label = 'train_loss')\n",
    "plt.plot(val_abserror_list,label = 'val_loss' )\n",
    "plt.title('q network model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('train steps*1000')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
